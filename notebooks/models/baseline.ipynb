{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from sneakers_ml.features.features import get_train_val_test\n",
    "from sneakers_ml.models.onnx import save_sklearn_onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, x_test, y_train, y_val, y_test = get_train_val_test(\"data/features/brands-classification-splits\", \"hog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.2851817334575955\n",
      "F1-weighted: 0.12656361194782342\n",
      "F1-macro: 0.03413845038210521\n"
     ]
    }
   ],
   "source": [
    "model = DummyClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "pred = model.predict(x_test)\n",
    "print(f\"Acc: {accuracy_score(y_test, pred)}\")\n",
    "print(f\"F1-weighted: {f1_score(y_test,pred,average='weighted')}\")\n",
    "print(f\"F1-macro: {f1_score(y_test,pred,average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "MissingShapeCalculator",
     "evalue": "Unable to find a shape calculator for type '<class 'sklearn.dummy.DummyClassifier'>'.\nIt usually means the pipeline being converted contains a\ntransformer or a predictor with no corresponding converter\nimplemented in sklearn-onnx. If the converted is implemented\nin another library, you need to register\nthe converted so that it can be used by sklearn-onnx (function\nupdate_registered_converter). If the model is not yet covered\nby sklearn-onnx, you may raise an issue to\nhttps://github.com/onnx/sklearn-onnx/issues\nto get the converter implemented or even contribute to the\nproject. If the model is a custom model, a new converter must\nbe implemented. Examples can be found in the gallery.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMissingShapeCalculator\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msave_sklearn_onnx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/models/brands-classification/dummy.onnx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Github/sneakers-ml/sneakers_ml/models/onnx.py:10\u001b[0m, in \u001b[0;36msave_sklearn_onnx\u001b[0;34m(model, x, path)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_sklearn_onnx\u001b[39m(model: Any, x: np\u001b[38;5;241m.\u001b[39mndarray, path: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 10\u001b[0m     onx \u001b[38;5;241m=\u001b[39m \u001b[43mto_onnx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Path(path)\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     12\u001b[0m         file\u001b[38;5;241m.\u001b[39mwrite(onx\u001b[38;5;241m.\u001b[39mSerializeToString())\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/sneakers-ml-hflTz_mY-py3.9/lib/python3.9/site-packages/skl2onnx/convert.py:306\u001b[0m, in \u001b[0;36mto_onnx\u001b[0;34m(model, X, name, initial_types, target_opset, options, white_op, black_op, final_types, dtype, naming, model_optim, verbose)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[to_onnx] initial_types=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m initial_types)\n\u001b[0;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_sklearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_opset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_opset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhite_op\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhite_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblack_op\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblack_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfinal_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinal_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnaming\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_optim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_optim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/sneakers-ml-hflTz_mY-py3.9/lib/python3.9/site-packages/skl2onnx/convert.py:208\u001b[0m, in \u001b[0;36mconvert_sklearn\u001b[0;34m(model, name, initial_types, doc_string, target_opset, custom_conversion_functions, custom_shape_calculators, custom_parsers, options, intermediate, white_op, black_op, final_types, dtype, naming, model_optim, verbose)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[convert_sklearn] convert_topology\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 208\u001b[0m onnx_model \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_topology\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtopology\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoc_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_opset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremove_identity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_optim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mintermediate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[convert_sklearn] end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/sneakers-ml-hflTz_mY-py3.9/lib/python3.9/site-packages/skl2onnx/common/_topology.py:1532\u001b[0m, in \u001b[0;36mconvert_topology\u001b[0;34m(topology, model_name, doc_string, target_opset, options, remove_identity, verbose)\u001b[0m\n\u001b[1;32m   1521\u001b[0m container \u001b[38;5;241m=\u001b[39m ModelComponentContainer(\n\u001b[1;32m   1522\u001b[0m     target_opset,\n\u001b[1;32m   1523\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1527\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m   1528\u001b[0m )\n\u001b[1;32m   1530\u001b[0m \u001b[38;5;66;03m# Traverse the graph from roots to leaves\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;66;03m# This loop could eventually be parallelized.\u001b[39;00m\n\u001b[0;32m-> 1532\u001b[0m \u001b[43mtopology\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_operators\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontainer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1533\u001b[0m container\u001b[38;5;241m.\u001b[39mensure_topological_order()\n\u001b[1;32m   1535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(container\u001b[38;5;241m.\u001b[39minputs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/sneakers-ml-hflTz_mY-py3.9/lib/python3.9/site-packages/skl2onnx/common/_topology.py:1349\u001b[0m, in \u001b[0;36mTopology.convert_operators\u001b[0;34m(self, container, verbose)\u001b[0m\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m variable \u001b[38;5;129;01min\u001b[39;00m operator\u001b[38;5;241m.\u001b[39moutputs:\n\u001b[1;32m   1347\u001b[0m     _check_variable_out_(variable, operator)\n\u001b[0;32m-> 1349\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_shape_calculator\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1350\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_converter(operator, container, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[1;32m   1352\u001b[0m \u001b[38;5;66;03m# If an operator contains a sequence of operators,\u001b[39;00m\n\u001b[1;32m   1353\u001b[0m \u001b[38;5;66;03m# output variables are not necessarily known at this stage.\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/sneakers-ml-hflTz_mY-py3.9/lib/python3.9/site-packages/skl2onnx/common/_topology.py:1164\u001b[0m, in \u001b[0;36mTopology.call_shape_calculator\u001b[0;34m(self, operator)\u001b[0m\n\u001b[1;32m   1162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1163\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Shape2] call infer_types for \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, operator)\n\u001b[0;32m-> 1164\u001b[0m     \u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_types\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/sneakers-ml-hflTz_mY-py3.9/lib/python3.9/site-packages/skl2onnx/common/_topology.py:630\u001b[0m, in \u001b[0;36mOperator.infer_types\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minfer_types\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# Invoke a core inference function\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 630\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MissingShapeCalculator(\n\u001b[1;32m    631\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to find a shape calculator for type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    632\u001b[0m                 \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_operator)\n\u001b[1;32m    633\u001b[0m             )\n\u001b[1;32m    634\u001b[0m         )\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    636\u001b[0m         shape_calc \u001b[38;5;241m=\u001b[39m _registration\u001b[38;5;241m.\u001b[39mget_shape_calculator(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype)\n",
      "\u001b[0;31mMissingShapeCalculator\u001b[0m: Unable to find a shape calculator for type '<class 'sklearn.dummy.DummyClassifier'>'.\nIt usually means the pipeline being converted contains a\ntransformer or a predictor with no corresponding converter\nimplemented in sklearn-onnx. If the converted is implemented\nin another library, you need to register\nthe converted so that it can be used by sklearn-onnx (function\nupdate_registered_converter). If the model is not yet covered\nby sklearn-onnx, you may raise an issue to\nhttps://github.com/onnx/sklearn-onnx/issues\nto get the converter implemented or even contribute to the\nproject. If the model is a custom model, a new converter must\nbe implemented. Examples can be found in the gallery.\n"
     ]
    }
   ],
   "source": [
    "save_sklearn_onnx(model, x_train, \"data/models/brands-classification/dummy.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sneakers-ml-hflTz_mY-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
