{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import wandb\n",
    "from PIL import Image\n",
    "from scipy.special import softmax\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torcheval.metrics.functional import multiclass_f1_score\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models import ResNet152_Weights, resnet152\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sneakers_ml.models.onnx_utils import get_session, predict, save_torch_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = ResNet152_Weights.DEFAULT\n",
    "preprocess = weights.transforms()\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "train = \"data/training/brands-classification-splits/train\"\n",
    "val = \"data/training/brands-classification-splits/val\"\n",
    "test = \"data/training/brands-classification-splits/test\"\n",
    "\n",
    "train_dataset = ImageFolder(train, transform=preprocess)\n",
    "val_dataset = ImageFolder(val, transform=preprocess)\n",
    "test_dataset = ImageFolder(test, transform=preprocess)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True, drop_last=False, num_workers=4)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=128, shuffle=False, drop_last=False, num_workers=4)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False, drop_last=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/models/brands-classification/resnet152-finetune-classes.npy\"\n",
    "save_path = Path(path)\n",
    "save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "class_to_idx = train_dataset.class_to_idx\n",
    "with save_path.open(\"wb\") as save_file:\n",
    "    np.save(save_file, np.array(list(class_to_idx.items())), allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet152Classifier(nn.Module):\n",
    "    def __init__(self, num_classes: int) -> None:\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        weights = ResNet152_Weights.DEFAULT\n",
    "        backbone = resnet152(weights=weights)\n",
    "        num_filters = backbone.fc.in_features\n",
    "        backbone.fc = nn.Linear(num_filters, self.num_classes)\n",
    "        extractor_layers = list(backbone.children())[:-3]\n",
    "        trainable_bottleneck_layers = list(backbone.children())[-3:-1]\n",
    "        classifier_layer = list(backbone.children())[-1]\n",
    "        self.feature_extractor = nn.Sequential(*extractor_layers)\n",
    "        self.feature_extractor.eval()\n",
    "\n",
    "        self.trainable_bottleneck = nn.Sequential(*trainable_bottleneck_layers)\n",
    "        self.classifier = nn.Sequential(classifier_layer)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        with torch.no_grad():\n",
    "            x = self.feature_extractor(x)\n",
    "        x = self.trainable_bottleneck(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(train_dataset.classes)\n",
    "model = ResNet152Classifier(num_classes)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    [{\"params\": model.trainable_bottleneck.parameters()}, {\"params\": model.classifier.parameters()}], lr=0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_pred: torch.Tensor, y_true: torch.Tensor):\n",
    "    f1_macro = multiclass_f1_score(y_pred, y_true, num_classes=num_classes, average=\"macro\")\n",
    "    f1_micro = multiclass_f1_score(y_pred, y_true, num_classes=num_classes, average=\"micro\")\n",
    "    f1_weighted = multiclass_f1_score(y_pred, y_true, num_classes=num_classes, average=\"weighted\")\n",
    "    return f1_macro.item(), f1_micro.item(), f1_weighted.item()\n",
    "\n",
    "\n",
    "def train_epoch(model, train_dataloader, criterion, optimizer):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    model.trainable_bottleneck.train()\n",
    "    model.classifier.train()\n",
    "\n",
    "    for data in tqdm(train_dataloader):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    return running_loss / len(train_dataloader)\n",
    "\n",
    "\n",
    "def eval_epoch(model, val_dataloader, criterion):\n",
    "    running_loss = 0.0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    model.trainable_bottleneck.eval()\n",
    "    model.classifier.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for data in tqdm(val_dataloader):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            y_true.append(labels.cpu())\n",
    "            y_pred.append(predicted.cpu())\n",
    "\n",
    "        y_true = torch.cat(y_true)\n",
    "        y_pred = torch.cat(y_pred)\n",
    "        f1_macro, f1_micro, f1_weighted = calculate_metrics(y_pred, y_true)\n",
    "\n",
    "        return running_loss / len(train_dataloader), f1_macro, f1_micro, f1_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"sneakers_ml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "\n",
    "def train(model, train_dataloader, criterion, optimizer, val_dataloader):\n",
    "    for _ in range(num_epochs):\n",
    "        train_loss = train_epoch(model, train_dataloader, criterion, optimizer)\n",
    "        val_loss, f1_macro, f1_micro, f1_weighted = eval_epoch(model, val_dataloader, criterion)\n",
    "        wandb.log(\n",
    "            {\n",
    "                \"val_f1_macro\": f1_macro,\n",
    "                \"val_f1_micro\": f1_micro,\n",
    "                \"val_f1_weighted\": f1_weighted,\n",
    "                \"val_loss\": val_loss,\n",
    "                \"train_loss\": train_loss,\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, train_dataloader, criterion, optimizer, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, f1_macro, f1_micro, f1_weighted = eval_epoch(model, test_dataloader, criterion)\n",
    "print(\n",
    "    {\n",
    "        \"test_f1_macro\": f1_macro,\n",
    "        \"test_f1_micro\": f1_micro,\n",
    "        \"test_f1_weighted\": f1_weighted,\n",
    "        \"test_loss\": loss,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.to(\"cpu\")\n",
    "torch_input = torch.randn(1, 3, 224, 224)\n",
    "path = \"data/models/brands-classification/resnet152-finetune.onnx\"\n",
    "save_torch_model(model, torch_input, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_resnet(images: Image.Image) -> np.ndarray:\n",
    "    with Path(\"data/models/brands-classification/resnet152-finetune-classes.npy\").open(\"rb\") as file:\n",
    "        class_to_idx_numpy = np.load(file, allow_pickle=False)\n",
    "        class_to_idx = dict(zip(class_to_idx_numpy[:, 1].astype(int), class_to_idx_numpy[:, 0]))\n",
    "\n",
    "    weights = ResNet152_Weights.DEFAULT\n",
    "    preprocess = weights.transforms()\n",
    "\n",
    "    def apply_transforms(image: Image.Image) -> torch.Tensor:\n",
    "        return preprocess(image)  # type: ignore[no-any-return]\n",
    "\n",
    "    preprocessed_images = torch.stack([apply_transforms(image) for image in images])\n",
    "\n",
    "    onnx_session = get_session(\"data/models/brands-classification/resnet152-finetune.onnx\", \"cpu\")\n",
    "\n",
    "    pred = predict(onnx_session, preprocessed_images)\n",
    "    softmax_pred = softmax(pred, axis=1)\n",
    "    predictions = np.argmax(softmax_pred, axis=1)\n",
    "    string_predictions = np.vectorize(class_to_idx.get)(predictions)\n",
    "    return predictions, string_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"data/training/brands-classification-splits/train/adidas/1.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_resnet([image, image])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sneakers-ml-hflTz_mY-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
