{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefeb28d4e8abb21",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# import pickle\n",
    "\n",
    "\n",
    "# fix for pycharm jupyter\n",
    "if not os.path.abspath(os.curdir).endswith(\"sneakers-ml\"):\n",
    "    os.chdir(\"../../\")\n",
    "\n",
    "os.path.abspath(os.curdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96e4465e44ae6c3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test\n",
    "\n",
    "img = cv2.imread(\"data/merged/images/by-brands/asics/0.jpeg\")\n",
    "imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "sift = cv2.SIFT_create()\n",
    "keypoints, descriptors = sift.detectAndCompute(img, None)\n",
    "sift_image = cv2.drawKeypoints(imgGray, keypoints, img)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(sift_image, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feee9b44ef0920ad",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# https://www.codespeedy.com/find-similarity-between-two-images-in-python/\n",
    "# https://stackoverflow.com/questions/50217364/sift-comparison-calculate-similarity-score-python\n",
    "# https://stackoverflow.com/questions/43220408/measure-of-image-similarity-for-feature-matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8338e67998b50927",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 1. SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f601b390ce34f659",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/merged/metadata/brands_dataset.csv\")\n",
    "df.drop(\"unique_images_count\", axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420ce6c8421c9e0c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# flat map dataset into brand -> images\n",
    "df[\"image_path\"] = df[\"images\"].apply(lambda path: [os.path.join(path, file) for file in os.listdir(path)])\n",
    "df.drop(\"images\", axis=1, inplace=True)\n",
    "df = df.explode(\"image_path\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2fd1b34b4dc5a8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "def calc_sift_similarity(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        return None\n",
    "    image8bit = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX).astype(\"uint8\")\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(image8bit, None)\n",
    "    return keypoints, descriptors\n",
    "\n",
    "\n",
    "df[\"keypoints\"], df[\"descriptors\"] = zip(*df[\"image_path\"].progress_apply(calc_sift_similarity))\n",
    "\n",
    "# pickle.dump(df, open(\"data/features/brands_dataset_sift.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f80ef8aafa22f9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 2. Image similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d693d8bc34415cd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img1, keypoints1 = cv2.imread(df.iloc[0][\"image_path\"]), df.iloc[0][\"keypoints\"]\n",
    "img2, keypoints2 = cv2.imread(df.iloc[1][\"image_path\"]), df.iloc[1][\"keypoints\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d290706909f9ed0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bf = cv2.BFMatcher(cv2.NORM_L1, crossCheck=True)\n",
    "matches = bf.match(df.iloc[0][\"descriptors\"], df.iloc[1][\"descriptors\"])\n",
    "matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "plt.imshow(\n",
    "    cv2.drawMatches(\n",
    "        img1, keypoints1, img2, keypoints2, matches[:10], None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS\n",
    "    )\n",
    ")\n",
    "plt.title(\"BFMatcher comparation of two sneakers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b936dee3beab78a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flann = cv2.FlannBasedMatcher({\"algorithm\": 0, \"trees\": 5}, {})\n",
    "matches = flann.knnMatch(df.iloc[0][\"descriptors\"], df.iloc[1][\"descriptors\"], k=2)\n",
    "\n",
    "plt.imshow(cv2.drawMatchesKnn(img1, keypoints1, img2, keypoints2, matches, None))\n",
    "plt.title(\"FlannBasedMatcher comparation of two sneakers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f524b2dc184f0c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def flann_match(\n",
    "    df: pd.DataFrame, example: pd.Series, distance_threshold: float = 0.7, good_count: int = 10, k: int = 2\n",
    "):\n",
    "    for _, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        if example[\"image_path\"] == row[\"image_path\"]:\n",
    "            continue\n",
    "\n",
    "        matches = flann.knnMatch(example[\"descriptors\"], row[\"descriptors\"], k=k)\n",
    "        good = []\n",
    "        for m, n in matches:\n",
    "            if m.distance < distance_threshold * n.distance:\n",
    "                good.append([m])\n",
    "\n",
    "        if len(good) > good_count:\n",
    "            return row\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3b2f2abeec9007",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# take 1 image and find most similar\n",
    "\n",
    "\n",
    "example_index = 1\n",
    "example = df.iloc[example_index]\n",
    "\n",
    "print(\"Trying to find match for:\", example[\"image_path\"])\n",
    "match = flann_match(shuffle(df), example, distance_threshold=0.7, k=2, good_count=50)\n",
    "\n",
    "if match is not None:\n",
    "    print(f\"Found match: {match['image_path']}\")\n",
    "    f = plt.figure()\n",
    "    f.add_subplot(1, 2, 1)\n",
    "    plt.imshow(cv2.imread(example[\"image_path\"]))\n",
    "    f.add_subplot(1, 2, 2)\n",
    "    plt.imshow(cv2.imread(match[\"image_path\"]))\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No match found\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
